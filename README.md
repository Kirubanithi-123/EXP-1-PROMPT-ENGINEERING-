# EXP-1-PROMPT-ENGINEERING-

## Aim: 
Comprehensive Report on the Fundamentals of Generative AI and Large Language Models (LLMs)
Experiment: Develop a comprehensive report for the following exercises:

Explain the foundational concepts of Generative AI.
Focusing on Generative AI architectures. (like transformers).
Generative AI applications.
Generative AI impact of scaling in LLMs.

## Algorithm:

Step 1: Input the initial text prompt.

Step 2: Tokenize the text into numeric tokens.

Step 3: Convert tokens to embeddings and add positional encoding.

Step 4: Pass embeddings through transformer layers with self-attention and feed-forward networks.

Step 5: Compute probabilities of the next token using softmax.

Step 6: Sample the next token using greedy or top-k/top-p decoding.

Step 7: Append the generated token to the sequence.

Step 8: Repeat Steps 4â€“7 until end-of-sequence or maximum length.

Step 9: Detokenize tokens to get the final generated text.

## Output

[EXP.1.pdf](https://github.com/user-attachments/files/22057058/EXP.1.pdf)



## Result

The experiment showed that prompt design greatly improves the quality of outputs from LLMs. It successfully demonstrated Generative AI concepts, architectures, applications, and scaling impacts.
